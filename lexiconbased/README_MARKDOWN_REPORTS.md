# Indonesian Sentiment Analysis - Markdown Report Generation

This module provides comprehensive comparison between Indonesian Naive Bayes Analyzer and VADER Indonesia with professional markdown report generation.

## ğŸš€ Quick Start

### Generate Full Comparison Report

```bash
python generate_markdown_report.py
```

### Generate Reports Programmatically

```python
from sentiment_analyzer_comparison import SentimentAnalyzerComparison

# Create comparison instance
comparison = SentimentAnalyzerComparison()

# Run comprehensive comparison
results = comparison.run_comprehensive_comparison()

# Generate markdown report
markdown_report = comparison.generate_detailed_report(format='markdown')

# Generate text report
text_report = comparison.generate_detailed_report(format='text')
```

## ğŸ“‹ Report Features

### ğŸ“Š Comprehensive Analysis

The generated markdown report includes:

1. **Executive Summary**
   - Overall winner determination
   - Key performance metrics comparison
   - Critical findings summary

2. **Performance Comparison Tables**
   - Training data performance metrics
   - Challenging cases performance
   - Class-wise performance breakdown

3. **Speed Analysis**
   - Training time comparison
   - Prediction speed benchmarks
   - Statistical significance testing

4. **Method Agreement Analysis**
   - Agreement rate calculation
   - Disagreement pattern analysis
   - Error distribution analysis

5. **Strengths & Weaknesses**
   - Detailed pros/cons for each method
   - Use case recommendations
   - Technical limitations

6. **Actionable Recommendations**
   - Primary method recommendation
   - Alternative approaches
   - Ensemble method suggestions

7. **Technical Details**
   - Dataset composition
   - Model configuration
   - Implementation specifics

## ğŸ“ Generated Files

### Markdown Report (`sentiment_analysis_comparison_report.md`)

Professional markdown report with:
- âœ… Rich formatting with tables and emojis
- âœ… GitHub-compatible markdown syntax
- âœ… Professional structure and layout
- âœ… Actionable insights and recommendations
- âœ… Technical documentation quality

### Text Report (`sentiment_analysis_comparison_report.txt`)

Plain text version with:
- âœ… Console-friendly formatting
- âœ… Simple structure for quick reading
- âœ… Essential metrics and recommendations

## ğŸ¯ Sample Report Structure

```markdown
# Indonesian Sentiment Analysis Comparison Report

## ğŸ¯ Executive Summary
- Overall winner determination
- Key metrics comparison table

## ğŸ“Š Performance Comparison
### Training Data Performance
| Metric | Naive Bayes | VADER | Winner |
|--------|-------------|-------|--------|
| Accuracy | 0.8500 | 0.7800 | NB |

### Challenging Cases Performance
- Complex sentiment handling
- Sarcasm and irony detection
- Negation handling evaluation

## âš¡ Speed Analysis
- Training time comparison
- Prediction speed benchmarks
- Performance vs speed trade-offs

## ğŸ¤ Method Agreement Analysis
- Agreement rate calculation
- Disagreement pattern analysis

## ğŸ’ª Strengths and Weaknesses
### Indonesian Naive Bayes
**Strengths:** âœ… High accuracy, âœ… Domain adaptation
**Weaknesses:** âŒ Training required, âŒ Slower predictions

### VADER Indonesia
**Strengths:** âœ… No training, âœ… Fast predictions
**Weaknesses:** âŒ Limited adaptability

## ğŸ¯ Recommendations
- Primary method recommendation
- Use case guidelines
- Alternative approaches
```

## ğŸ”§ Technical Implementation

### Comparison Framework Features

1. **Multi-Dataset Testing**
   - Training data (45 samples)
   - Challenging cases (15 samples)
   - Balanced sentiment distribution

2. **Comprehensive Metrics**
   - Accuracy, Precision, Recall, F1-Score
   - Class-wise performance analysis
   - Speed benchmarking

3. **Advanced Analysis**
   - Method agreement calculation
   - Disagreement pattern analysis
   - Confidence score evaluation

4. **Professional Reporting**
   - Markdown and text formats
   - Rich formatting and tables
   - Actionable recommendations

### Dataset Composition

**Training Data (45 samples):**
- Movie reviews (15 samples)
- Product reviews (15 samples)
- Social media posts (15 samples)
- Balanced: 15 positive, 15 negative, 15 neutral

**Challenging Cases (15 samples):**
- Mixed sentiments
- Sarcasm and irony
- Negation handling
- Intensifiers
- Colloquial Indonesian

## ğŸ“ˆ Performance Metrics

### Evaluation Criteria

1. **Accuracy Metrics**
   - Overall accuracy
   - Class-wise precision/recall
   - F1-score (weighted average)

2. **Speed Metrics**
   - Training time (Naive Bayes only)
   - Average prediction time
   - Standard deviation of prediction times

3. **Robustness Metrics**
   - Performance on challenging cases
   - Method agreement rate
   - Confidence calibration

## ğŸ¨ Visualization Support

The framework also generates:
- Performance comparison charts
- Confusion matrices
- Speed comparison plots
- Agreement analysis visualizations
- Feature importance plots

## ğŸš€ Usage Examples

### Basic Report Generation

```python
# Quick report generation
comparison = SentimentAnalyzerComparison()
results = comparison.run_comprehensive_comparison()
markdown_report = comparison.generate_detailed_report(format='markdown')
```

### Custom Analysis

```python
# Custom dataset analysis
comparison = SentimentAnalyzerComparison()
comparison.initialize_analyzers()

# Use your own data
custom_texts = ["Your Indonesian texts here..."]
custom_labels = ["positive", "negative", "neutral"]

# Train and evaluate
comparison.nb_analyzer.train(custom_texts, custom_labels)
# ... run comparison with custom data
```

### Preview Generation

```python
# Generate quick preview
python generate_markdown_report.py
# Choose option 2 for preview
```

## ğŸ“‹ Requirements

- Python 3.7+
- pandas, numpy, scikit-learn
- matplotlib, seaborn (for visualizations)
- requests (for lexicon loading)

## ğŸ¯ Best Practices

1. **Data Quality**
   - Use balanced datasets for training
   - Include diverse text types
   - Test on domain-specific data

2. **Evaluation**
   - Run multiple iterations for stability
   - Test on challenging cases
   - Consider real-world deployment scenarios

3. **Reporting**
   - Generate both markdown and text reports
   - Include visualizations for presentations
   - Document methodology and limitations

## ğŸ” Sample Output

See `sample_report.md` for a complete example of the generated markdown report.

## ğŸ“ Support

For issues or questions about the markdown report generation:
1. Check the sample report for expected output format
2. Run the preview mode for quick testing
3. Verify all dependencies are installed
4. Ensure Indonesian lexicon sources are accessible

---

*Professional sentiment analysis comparison with publication-ready markdown reports*
